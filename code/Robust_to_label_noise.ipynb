{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMggBfRoDF6S4GTOKlhT0Pf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pengwei-Yang/Robust-to-noisy-data/blob/main/Robust_to_label_noise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load data"
      ],
      "metadata": {
        "id": "Ddx_NF6VlQ5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from collections import OrderedDict"
      ],
      "metadata": {
        "id": "fTxfmbsqxV1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class A2Dataset(Dataset):\n",
        "    r\"\"\"Self-defined child class of the pytorch Dataset object.\n",
        "    \"\"\"\n",
        "    def __init__(self, data, labels, transform=None):\n",
        "        self.data = np.asarray(data)\n",
        "        self.labels = np.asarray(labels)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "        #Img should be PIL Image\n",
        "        #Transfrom numpy array to PIL\n",
        "        if len(data.shape) == 3:\n",
        "            data = Image.fromarray(np.uint8(data)).convert('RGB')\n",
        "        else:\n",
        "            data = Image.fromarray(np.uint8(data)).convert('L')\n",
        "\n",
        "        if self.transform is not None:\n",
        "              data = self.transform(data)\n",
        "        return (data, label)\n",
        "\n",
        "def train_valid_random_split(data, fracs, labels):\n",
        "    r\"\"\"Splitting data to training data and validation data.\n",
        "    Args:\n",
        "        data: 3 dimension, E.g.,(18000, 28, 28)\n",
        "        labels: 1 dimension, E.g.,(18000,)\n",
        "    Returns:\n",
        "        shuffled_data: 3 dimension\n",
        "        shuffled_labels: 1 dimension\n",
        "    \"\"\"\n",
        "    #Assert for debugging\n",
        "    assert len(fracs) == 2\n",
        "    assert sum(fracs) == 1\n",
        "    assert all(frac > 0 for frac in fracs)\n",
        "    nn = len(data)\n",
        "    subset_lens = [int(frac*nn) for frac in fracs]\n",
        "    idxs = list(range(nn))\n",
        "    #Shuffle index\n",
        "    random.shuffle(idxs)\n",
        "    shuffled_data = []\n",
        "    shuffled_labels=[]\n",
        "    start_idx = 0\n",
        "    #Shuffle data and labels/ or using np.random.permutation() + SubsetRandomSampler()\n",
        "    for subset_len in subset_lens:\n",
        "        end_idx = start_idx + subset_len\n",
        "        cur_idxs = idxs[start_idx:end_idx]\n",
        "        shuffled_data.append(data[cur_idxs,:,:].tolist())\n",
        "        shuffled_labels.append(labels[cur_idxs].tolist())\n",
        "        start_idx = end_idx\n",
        "    return shuffled_data, shuffled_labels\n",
        "\n",
        "def get_loader(batch_size = 128, num_workers = 1, proportion = [0.8,0.2], file_path=None, transform=None):\n",
        "    r\"\"\"This function aims to read the data file and split the data into two subsets, i.e,\n",
        "    train data, validation data, and return their DataLoader objects.\n",
        "    Args:\n",
        "        file_path: path of the dataset\n",
        "        batch_size: one of the hyperparameters 128 or 64 or ...\n",
        "        num_workers: amount of threads, default=0->main thread\n",
        "        transfrom: Data preprocessing\n",
        "    \"\"\"\n",
        "    #Split and transform data\n",
        "    #[train_data, val_data] = train_valid_random_split(train_val_data, fracs = proportion)\n",
        "    dataset = np.load(file_path)\n",
        "\n",
        "    Xtr_val = dataset['Xtr']\n",
        "    Str_val = dataset['Str']\n",
        "    Xts = dataset['Xts']\n",
        "    Yts = dataset['Yts']\n",
        "\n",
        "    train_val_data = Xtr_val\n",
        "    train_labels = Str_val\n",
        "    test_data = Xts\n",
        "    test_labels = Yts\n",
        "\n",
        "    shuffled_data, shuffled_labels = train_valid_random_split(data=train_val_data, labels=train_labels, fracs = proportion)\n",
        "    train_data = shuffled_data[0]\n",
        "    val_data = shuffled_data[1]\n",
        "    train_label = shuffled_labels[0]\n",
        "    test_label = shuffled_labels[1]\n",
        "\n",
        "    train_data = A2Dataset(data = train_data, labels=train_label, transform=transform)\n",
        "    val_data = A2Dataset(data = val_data, labels=test_label, transform=transform)\n",
        "    test_data = A2Dataset(data = test_data, labels=test_labels, transform=transform)\n",
        "\n",
        "    #DataLoader-->Return batch of data, choose number of threads etc.\n",
        "    train_loader = DataLoader(\n",
        "        train_data,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        drop_last=False,\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_data,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        drop_last=False,\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_data,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        drop_last=False,\n",
        "    )\n",
        "    return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "WSmOFtril_IX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LeNet-5 Backbone\n",
        "#Defining the convolutional neural network\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self, num_class, transition_matrix=None):\n",
        "        super(LeNet5, self).__init__()\n",
        "\n",
        "        self.transition_matrix = transition_matrix\n",
        "        # if self.transition_matrix is None:\n",
        "        #     self.transition_matrix = torch.eye(num_class)\n",
        "        # if self.transition_matrix is not None:\n",
        "        #     assert(num_class == transition_matrix.shape[0] and num_class == transition_matrix.shape[1] and num_class == transition_matrix.shape[2])\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(6),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(400, 120),\n",
        "            nn.ReLU(),  #nn.ReLU(inplace=True) can sometimes save memory, but destroy input data\n",
        "            nn.Linear(120, 84),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(84, num_class)\n",
        "        )\n",
        "\n",
        "    def backward_learning(self, x):\n",
        "        if self.transition_matrix != None:\n",
        "            if x.is_cuda:\n",
        "                y_clean = torch.mm(self.transition_matrix.cuda().inverse(), x.T).T\n",
        "            else:\n",
        "                y_clean = torch.mm(self.transition_matrix.inverse(), x.T).T\n",
        "            return y_clean\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.shape[0], -1) #flatten\n",
        "        out = self.classifier(out)\n",
        "        out = self.backward_learning(out) #Noisy posterior-->Clean posterior\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZSFp0j9USphO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=3, transition_matrix=None):\n",
        "        super(AlexNet, self).__init__()\n",
        "\n",
        "        self.transition_matrix = transition_matrix\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=0),\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU())\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(9216, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, num_classes))\n",
        "\n",
        "    def backward_learning(self, x):\n",
        "        if self.transition_matrix != None:\n",
        "            if x.is_cuda:\n",
        "                y_clean = torch.mm(self.transition_matrix.cuda().inverse(), x.T).T\n",
        "            else:\n",
        "                y_clean = torch.mm(self.transition_matrix.inverse(), x.T).T\n",
        "            return y_clean\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.backward_learning(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "wsBBno12LUFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# When all random seeds are fixed, the python runtime environment becomes deterministic.\n",
        "def seed_torch(seed=1000):\n",
        "    r\"\"\"Fix all random seeds for repeating the expriement result.\"\"\"\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # If multi-GPUs are used.\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "# Embedding labels to one-hot form.\n",
        "def one_hot_embedding(labels, num_classes):\n",
        "    r\"\"\"Embedding labels to one-hot form.\n",
        "\n",
        "    Args:\n",
        "      labels: (LongTensor) class labels, sized [N,].\n",
        "      num_classes: (int) number of classes.\n",
        "\n",
        "    Returns:\n",
        "      (tensor) encoded labels, sized [N, #classes].\n",
        "    \"\"\"\n",
        "    y = torch.eye(num_classes)\n",
        "    return y[labels]\n",
        "\n",
        "\n",
        "# Calcuate the accuracy according to the prediction and the true label.\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    r\"\"\"Computes the precision@k for the specified values of k.\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "\n",
        "\n",
        "# A helper function which is used to record the experiment results.\n",
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, num):\n",
        "        self.val = val\n",
        "        self.sum += val * num\n",
        "        self.count += num\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "# # Load a NN model.\n",
        "# def load_model(m_config):\n",
        "#     model = globals()[m_config['model_name']](\n",
        "#         input_dim=m_config[\"input_dim\"],\n",
        "#         hidden_dim=m_config[\"hidden_dim\"],\n",
        "#         output_dim=m_config[\"output_dim\"]\n",
        "#     )\n",
        "#     return model"
      ],
      "metadata": {
        "id": "xUAyNb_fbkaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training and validation functions"
      ],
      "metadata": {
        "id": "G4Nsqw4Ecp6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch, model, optimizer, criterion, train_loader):\n",
        "    \"\"\"Training a pytorch nn_model.\"\"\"\n",
        "    top1_acc_meter = AverageMeter()\n",
        "    loss_meter = AverageMeter()\n",
        "\n",
        "    # swith model to to train mode\n",
        "    model.train()\n",
        "    for step, (data, targets) in enumerate(train_loader):\n",
        "        # prepare min_batch\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # predict\n",
        "        preds = model(data)\n",
        "\n",
        "        # forward\n",
        "        loss = criterion(preds, targets)\n",
        "\n",
        "        # set all gradients to zero\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # backward\n",
        "        loss.backward()\n",
        "\n",
        "        # update all gradients\n",
        "        optimizer.step()\n",
        "\n",
        "        # calculate accuracy\n",
        "        [top1_acc] = accuracy(preds.data, targets.data, topk=(1,))\n",
        "        # record accuary and cross entropy losss\n",
        "        min_batch_size = data.size(0)\n",
        "        top1_acc_meter.update(top1_acc.item(), min_batch_size)\n",
        "        loss_meter.update(loss.item(), min_batch_size)\n",
        "\n",
        "    print(\"Train \",\"accuracy->%.2f\" %top1_acc_meter.avg, \"loss->%.2f\" %loss_meter.avg)\n",
        "\n",
        "\n",
        "def validate_and_test(epoch, model, criterion, val_loader, is_test=False):\n",
        "    \"\"\"Validation or testing of a nn_model.\"\"\"\n",
        "    top1_acc_meter = AverageMeter()\n",
        "    loss_meter = AverageMeter()\n",
        "\n",
        "    # swith model to to eval mode\n",
        "    # if is_test==False:\n",
        "\n",
        "    model.eval()\n",
        "    for step, (data, targets) in enumerate(val_loader): #in this val & test function, we dont write backward here\n",
        "        # prepare min_batch\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # predict\n",
        "        with torch.no_grad():\n",
        "            preds = model(data)\n",
        "\n",
        "        # forward\n",
        "        loss = criterion(preds, targets)\n",
        "\n",
        "        # calculate accuracy\n",
        "        [top1_acc] = accuracy(preds.data, targets.data, topk=(1,))\n",
        "\n",
        "        # record accuary and cross entropy losss\n",
        "        min_batch_size = data.size(0)\n",
        "        top1_acc_meter.update(top1_acc.item(), min_batch_size)\n",
        "        loss_meter.update(loss.item(), min_batch_size)\n",
        "\n",
        "    top1_acc_avg = top1_acc_meter.avg\n",
        "    loss_avg = loss_meter.avg\n",
        "    if(is_test == False):\n",
        "        print(\"Validate \", \"val_accuracy-->%.2f\" %top1_acc_avg, \"val_loss-->%.2f\" %loss_avg)\n",
        "    else:\n",
        "        print(\"Test Accuracy--->%.2f\" %top1_acc_avg, \"Test Loss--->%.2f\" %loss_avg)\n",
        "\n",
        "    return top1_acc_avg"
      ],
      "metadata": {
        "id": "BvkL8sSJctyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run training and validation\n",
        "# Some global variabiles\n",
        "device = None\n",
        "train_loader = None\n",
        "model = None\n",
        "# model_config = OrderedDict([\n",
        "#     ('model_name','Predefined_FCNet'),\n",
        "#     ('input_dim',10),\n",
        "#     ('hidden_dim',2),\n",
        "#     ('output_dim',2)\n",
        "# ])\n",
        "\n",
        "optim_config = OrderedDict([\n",
        "    #('epochs', 15),\n",
        "    ('batch_size', 128),\n",
        "    #('base_lr', 0.1),\n",
        "    ('weight_decay', 1e-5),\n",
        "    ('momentum', 0.9),\n",
        "    # ('lr_decay', 0.1)\n",
        "])\n",
        "\n",
        "run_config = OrderedDict([\n",
        "    ('seed', 1),\n",
        "    ('outdir', 'trained_model'),\n",
        "    ('num_workers', 1),\n",
        "])\n",
        "\n",
        "# data_config = OrderedDict([\n",
        "#     ('flip_rates', [0.15,0.25]),\n",
        "#     ('data_path', \"./input.data\"),\n",
        "#     ('train_val_test_split', [0.7,0.1,0.2])\n",
        "# ])\n",
        "\n",
        "net_parameters = OrderedDict([\n",
        "    # ('num_epochs', 10),\n",
        "    ('batch_size', 128),\n",
        "    ('lr', 0.002),\n",
        "    ('num_classes', 3)\n",
        "])\n",
        "\n",
        "config = OrderedDict([\n",
        "    # ('model_config', model_config),\n",
        "    ('optim_config', optim_config),\n",
        "    ('run_config', run_config),\n",
        "    # ('data_config', data_config),\n",
        "    ('net_parameters', net_parameters)\n",
        "])\n",
        "\n",
        "# #Initialize model parameters\n",
        "    # takes in a module and applies the specified weight initialization\n",
        "# def weights_init_uniform_rule(m):\n",
        "#     classname = m.__class__.__name__\n",
        "#     # for every Linear layer in a model..\n",
        "#     if classname.find('Linear') != -1:\n",
        "#         # get the number of the inputs\n",
        "#         n = m.in_features\n",
        "#         y = 1.0/np.sqrt(n)\n",
        "#         m.weight.data.uniform_(-y, y)\n",
        "#         m.bias.data.fill_(0)\n",
        "\n",
        "# Device will determine whether to run the training on GPU or CPU.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def run_train_val(train_loader, val_loader, test_loader, model_name, transition_matrix=None, lr=None, epoch_num=None):\n",
        "    global device\n",
        "    global config\n",
        "    # global train_loader\n",
        "    global model\n",
        "    best_top1_acc = 0\n",
        "    # check gpu\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    # configerations\n",
        "    run_config = config['run_config']\n",
        "    optim_config = config['optim_config']\n",
        "    # data_config = config['data_config']\n",
        "    net_parameters = config['net_parameters']\n",
        "\n",
        "    # set random seed->make the trained net of every turn different\n",
        "    seed_torch(run_config['seed'])\n",
        "\n",
        "    # create output directory\n",
        "    outdir = run_config['outdir']\n",
        "    if not os.path.exists(outdir):\n",
        "        os.makedirs(outdir)\n",
        "\n",
        "    # load data\n",
        "    # data = pd.read_csv(data_config[\"data_path\"], header = None).values.tolist()\n",
        "    # data = binary_CCN_generator(data = data, flip_rates = data_config[\"flip_rates\"])\n",
        "\n",
        "    # train_loader, val_loader, test_loader = get_loader(\n",
        "    #     batch_size = optim_config['batch_size'],\n",
        "    #     num_workers = run_config['num_workers'],\n",
        "    #     train_val_test_split = data_config['train_val_test_split'],\n",
        "    #     data = data\n",
        "    # )\n",
        "    # train_loader = train_loader\n",
        "    # val_loader = val_loader\n",
        "    # test_loader = test_loader\n",
        "\n",
        "    #Model\n",
        "    if model_name == 'LeNet':\n",
        "        model = LeNet5(net_parameters['num_classes'], transition_matrix=transition_matrix)\n",
        "    elif model_name == 'AlexNet':\n",
        "        model = AlexNet(net_parameters['num_classes'], transition_matrix=transition_matrix)\n",
        "    else:\n",
        "        print('Input Model Name Error!!!')\n",
        "        return 0\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        print(torch.cuda.device_count(), \"GPUs are used!\")\n",
        "        model = nn.DataParallel(model)\n",
        "    model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "    # criterion and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(\n",
        "        params = model.parameters(),\n",
        "        lr=lr,\n",
        "        momentum = optim_config['momentum'],\n",
        "        weight_decay = optim_config['weight_decay']\n",
        "    )\n",
        "    print(\"【New turn...】\")\n",
        "\n",
        "\n",
        "\n",
        "    for epoch in range(1, epoch_num + 1):\n",
        "        print(\"Epoch\", epoch, \"/\", epoch_num)\n",
        "        #train\n",
        "        train(epoch, model, optimizer, criterion, train_loader)\n",
        "\n",
        "        #validation\n",
        "        top1_acc_avg = validate_and_test(epoch, model, criterion, val_loader)\n",
        "\n",
        "\n",
        "        # save the best model so far\n",
        "        if (top1_acc_avg > best_top1_acc):\n",
        "            state = OrderedDict([\n",
        "                ('config', config),\n",
        "                ('state_dict', model.state_dict()),\n",
        "                ('optimizer', optimizer.state_dict()),\n",
        "                ('epoch', epoch),\n",
        "                ('top1-accuracy', top1_acc_avg),\n",
        "            ])\n",
        "            best_model_path = os.path.join(outdir, 'model_best.pth')\n",
        "            torch.save(state, best_model_path)\n",
        "            best_top1_acc = top1_acc_avg\n",
        "    #test->for one epoch\n",
        "    test_acc_avg = validate_and_test(epoch, model, criterion, test_loader, is_test=True) #test function without backpropogation\n",
        "\n",
        "\n",
        "\n",
        "    # return test_acc_avg\n",
        "    # model = LeNet5(net_parameters['num_classes'], transition_matrix=transition_matrix)\n",
        "    # model.load_state_dict(torch.load(best_model_path))\n",
        "    # model.eval()\n",
        "    # #model = torch.load(best_model_path)\n",
        "    # #test\n",
        "    # print(type(model))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n8oHCpVAeVso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MINIST-LeNet+ALexNet"
      ],
      "metadata": {
        "id": "vLGYOKuj88Ih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Choose transition matrix and input size based on input name --> MINIST05/MINIST06 and LeNet/AlexNet\n",
        "def MINIST(transform=None, batch_size=128, name=None):\n",
        "    file_path = None\n",
        "    print('Code Name: ', name)\n",
        "    if name == 'MINIST05_LeNet':\n",
        "        print('Setting: MINIST05_LeNet activated!')\n",
        "    #Transition matrix of MINIST05\n",
        "        transition_matrix = torch.Tensor(\n",
        "            [[0.5, 0.2, 0.3],\n",
        "            [0.3, 0.5, 0.2],\n",
        "            [0.2, 0.3, 0.5]]\n",
        "            )\n",
        "\n",
        "        file_path = \"/content/FashionMNIST0.5.npz\" #Input your own path of FashionMNIST0.5 here\n",
        "\n",
        "        #transform-Data preprocessing\n",
        "        if transform is None:\n",
        "            transform = transforms.Compose([\n",
        "                transforms.Resize((32,32)),\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5),(0.5)) #Only one channel (Grey image)[-1,+1]\n",
        "            ])\n",
        "\n",
        "    if name == 'MINIST05_AlexNet':\n",
        "        print('Setting: MINIST05_AlexNet activated!')\n",
        "          #Transition matrix of MINIST05\n",
        "        transition_matrix = torch.Tensor(\n",
        "            [[0.5, 0.2, 0.3],\n",
        "            [0.3, 0.5, 0.2],\n",
        "            [0.2, 0.3, 0.5]]\n",
        "            )\n",
        "\n",
        "        file_path = \"/content/FashionMNIST0.5.npz\" #Input your own path of FashionMNIST0.5 here\n",
        "\n",
        "        #transform-Data preprocessing\n",
        "        if transform is None:\n",
        "            transform = transforms.Compose([\n",
        "                transforms.Resize((227,227)),\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5),(0.5)) #Only one channel (Grey image)[-1,+1]\n",
        "            ])\n",
        "\n",
        "    if name == 'MINIST06_LeNet':\n",
        "        print('Setting: MINIST06_LeNet activated!')\n",
        "        #Transition matrix of MINIST06\n",
        "        transition_matrix = torch.Tensor(\n",
        "            [[0.4, 0.3, 0.3],\n",
        "            [0.3, 0.4, 0.3],\n",
        "            [0.3, 0.3, 0.4]]\n",
        "            )\n",
        "\n",
        "        file_path = \"/content/FashionMNIST0.6.npz\" #Input your own path of FashionMNIST0.5 here\n",
        "\n",
        "        #transform-Data preprocessing\n",
        "        if transform is None:\n",
        "            transform = transforms.Compose([\n",
        "                transforms.Resize((32,32)),\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5),(0.5)) #Only one channel (Grey image)[-1,+1]\n",
        "            ])\n",
        "\n",
        "    if name == 'MINIST06_AlexNet':\n",
        "        print('Setting: MINIST06_AlexNet activated!')\n",
        "        #Transition matrix of MINIST06\n",
        "        transition_matrix = torch.Tensor(\n",
        "            [[0.4, 0.3, 0.3],\n",
        "            [0.3, 0.4, 0.3],\n",
        "            [0.3, 0.3, 0.4]]\n",
        "            )\n",
        "\n",
        "        file_path = \"/content/FashionMNIST0.6.npz\" #Input your own path of FashionMNIST0.5 here\n",
        "\n",
        "        #transform-Data preprocessing\n",
        "        if transform is None:\n",
        "            transform = transforms.Compose([\n",
        "                transforms.Resize((227,227)),\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5),(0.5)) #Only one channel (Grey image)[-1,+1]\n",
        "            ])\n",
        "\n",
        "    train_loader, val_loader, test_loader = get_loader(file_path=file_path, transform=transform,batch_size=batch_size)\n",
        "\n",
        "    return transition_matrix, train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "IQ084rbqaoFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training and test"
      ],
      "metadata": {
        "id": "1vflegfDco66"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Classfier- LeNet"
      ],
      "metadata": {
        "id": "0dAtUSh_fxzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####DATASET: MINIST05\n",
        "\n",
        "####MODEL NAME: LeNet\n",
        "\n",
        "####NAME CODE: MINIST05_LeNet\n",
        "\n",
        "####STATUS: Without Backward Learning"
      ],
      "metadata": {
        "id": "OukEl8W58_SD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transition_matrix_M5_Le_N, train_M5_Le_N, val_M5_Le_N, test_M5_Le_N = MINIST(batch_size=512, name='MINIST05_LeNet')\n",
        "run_train_val(train_loader=train_M5_Le_N, val_loader=val_M5_Le_N, test_loader=test_M5_Le_N, model_name='LeNet', lr=0.08, epoch_num=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cVm2PO_IRcX",
        "outputId": "6307d785-f134-4716-c7b7-0bad72150661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code Name:  MINIST05_LeNet\n",
            "Setting: MINIST05_LeNet activated!\n",
            "【New turn...】\n",
            "Epoch 1 / 10\n",
            "Train  accuracy->43.49 loss->1.07\n",
            "Validate  val_accuracy-->46.25 val_loss-->1.06\n",
            "Epoch 2 / 10\n",
            "Train  accuracy->47.32 loss->1.05\n",
            "Validate  val_accuracy-->48.42 val_loss-->1.05\n",
            "Epoch 3 / 10\n",
            "Train  accuracy->47.64 loss->1.05\n",
            "Validate  val_accuracy-->48.39 val_loss-->1.05\n",
            "Epoch 4 / 10\n",
            "Train  accuracy->48.12 loss->1.04\n",
            "Validate  val_accuracy-->48.61 val_loss-->1.05\n",
            "Epoch 5 / 10\n",
            "Train  accuracy->48.43 loss->1.04\n",
            "Validate  val_accuracy-->48.58 val_loss-->1.05\n",
            "Epoch 6 / 10\n",
            "Train  accuracy->48.34 loss->1.04\n",
            "Validate  val_accuracy-->48.42 val_loss-->1.05\n",
            "Epoch 7 / 10\n",
            "Train  accuracy->48.40 loss->1.04\n",
            "Validate  val_accuracy-->48.36 val_loss-->1.05\n",
            "Epoch 8 / 10\n",
            "Train  accuracy->48.73 loss->1.04\n",
            "Validate  val_accuracy-->48.42 val_loss-->1.05\n",
            "Epoch 9 / 10\n",
            "Train  accuracy->48.69 loss->1.04\n",
            "Validate  val_accuracy-->48.17 val_loss-->1.05\n",
            "Epoch 10 / 10\n",
            "Train  accuracy->48.90 loss->1.04\n",
            "Validate  val_accuracy-->48.53 val_loss-->1.05\n",
            "Test Accuracy--->90.27 Test Loss--->0.80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####DATASET: MINIST05\n",
        "\n",
        "####MODEL NAME: LeNet\n",
        "\n",
        "####NAME CODE: MINIST05_LeNet\n",
        "\n",
        "####STATUS: With Backward Learning"
      ],
      "metadata": {
        "id": "9NgUqkI39D1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transition_matrix_M5_Le_Y, train_M5_Le_Y, val_M5_Le_Y, test_M5_Le_Y = MINIST(batch_size=512, name='MINIST05_LeNet')\n",
        "run_train_val(train_loader=train_M5_Le_Y, val_loader=val_M5_Le_Y, test_loader=test_M5_Le_Y, model_name='LeNet', transition_matrix=transition_matrix_M5_Le_Y, lr=0.08, epoch_num=9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcIT7bM8lr5O",
        "outputId": "153dbdce-e397-40b7-a4a4-4bf902654e7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code Name:  MINIST05_LeNet\n",
            "Setting: MINIST05_LeNet activated!\n",
            "【New turn...】\n",
            "Epoch 1 / 9\n",
            "Train  accuracy->41.12 loss->1.10\n",
            "Validate  val_accuracy-->42.67 val_loss-->1.08\n",
            "Epoch 2 / 9\n",
            "Train  accuracy->46.24 loss->1.06\n",
            "Validate  val_accuracy-->47.58 val_loss-->1.06\n",
            "Epoch 3 / 9\n",
            "Train  accuracy->46.84 loss->1.05\n",
            "Validate  val_accuracy-->47.83 val_loss-->1.06\n",
            "Epoch 4 / 9\n",
            "Train  accuracy->47.76 loss->1.05\n",
            "Validate  val_accuracy-->47.86 val_loss-->1.06\n",
            "Epoch 5 / 9\n",
            "Train  accuracy->48.03 loss->1.05\n",
            "Validate  val_accuracy-->48.03 val_loss-->1.06\n",
            "Epoch 6 / 9\n",
            "Train  accuracy->48.24 loss->1.05\n",
            "Validate  val_accuracy-->48.61 val_loss-->1.06\n",
            "Epoch 7 / 9\n",
            "Train  accuracy->48.35 loss->1.05\n",
            "Validate  val_accuracy-->48.61 val_loss-->1.06\n",
            "Epoch 8 / 9\n",
            "Train  accuracy->48.44 loss->1.04\n",
            "Validate  val_accuracy-->48.36 val_loss-->1.05\n",
            "Epoch 9 / 9\n",
            "Train  accuracy->48.76 loss->1.04\n",
            "Validate  val_accuracy-->48.50 val_loss-->1.06\n",
            "Test Accuracy--->91.30 Test Loss--->0.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####DATASET: MINIST06\n",
        "\n",
        "####MODEL NAME: LeNet\n",
        "\n",
        "####NAME CODE: MINIST06_LeNet\n",
        "\n",
        "####STATUS: Without Backward Learning"
      ],
      "metadata": {
        "id": "gmHVwUaKfhFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transition_matrix_M6_Le_N, train_M6_Le_N, val_M6_Le_N, test_M6_Le_N = MINIST(batch_size=128, name='MINIST06_LeNet')\n",
        "run_train_val(train_loader=train_M6_Le_N, val_loader=val_M6_Le_N, test_loader=test_M6_Le_N, model_name='LeNet', lr=0.0025, epoch_num=6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrgNRDSWfo8l",
        "outputId": "2b5c6b71-1350-4e36-ed66-a25e80b0427f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code Name:  MINIST06_LeNet\n",
            "Setting: MINIST06_LeNet activated!\n",
            "【New turn...】\n",
            "Epoch 1 / 6\n",
            "Train  accuracy->36.64 loss->1.10\n",
            "Validate  val_accuracy-->37.36 val_loss-->1.09\n",
            "Epoch 2 / 6\n",
            "Train  accuracy->38.55 loss->1.09\n",
            "Validate  val_accuracy-->37.11 val_loss-->1.09\n",
            "Epoch 3 / 6\n",
            "Train  accuracy->39.24 loss->1.09\n",
            "Validate  val_accuracy-->36.97 val_loss-->1.09\n",
            "Epoch 4 / 6\n",
            "Train  accuracy->39.26 loss->1.09\n",
            "Validate  val_accuracy-->36.92 val_loss-->1.09\n",
            "Epoch 5 / 6\n",
            "Train  accuracy->39.24 loss->1.09\n",
            "Validate  val_accuracy-->37.39 val_loss-->1.09\n",
            "Epoch 6 / 6\n",
            "Train  accuracy->39.41 loss->1.09\n",
            "Validate  val_accuracy-->37.75 val_loss-->1.09\n",
            "Test Accuracy--->87.57 Test Loss--->0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####DATASET: MINIST06\n",
        "\n",
        "####MODEL NAME: LeNet\n",
        "\n",
        "####NAME CODE: MINIST06_LeNet\n",
        "\n",
        "####STATUS: With Backward Learning"
      ],
      "metadata": {
        "id": "3kIp6mUufoQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transition_matrix_M6_Le_Y, train_M6_Le_Y, val_M6_Le_Y, test_M6_Le_Y = MINIST(batch_size=128, name='MINIST06_LeNet')\n",
        "run_train_val(train_loader=train_M6_Le_Y, val_loader=val_M6_Le_Y, test_loader=test_M6_Le_Y, model_name='LeNet', transition_matrix=transition_matrix_M6_Le_Y, lr=0.0025, epoch_num=6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jh-sx1JwgHpK",
        "outputId": "9825746d-d2b2-4c8b-e8a1-bce4f905cb44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code Name:  MINIST06_LeNet\n",
            "Setting: MINIST06_LeNet activated!\n",
            "【New turn...】\n",
            "Epoch 1 / 6\n",
            "Train  accuracy->35.47 loss->1.12\n",
            "Validate  val_accuracy-->36.56 val_loss-->1.10\n",
            "Epoch 2 / 6\n",
            "Train  accuracy->36.82 loss->1.10\n",
            "Validate  val_accuracy-->37.11 val_loss-->1.10\n",
            "Epoch 3 / 6\n",
            "Train  accuracy->37.32 loss->1.10\n",
            "Validate  val_accuracy-->37.39 val_loss-->1.10\n",
            "Epoch 4 / 6\n",
            "Train  accuracy->37.81 loss->1.09\n",
            "Validate  val_accuracy-->37.22 val_loss-->1.10\n",
            "Epoch 5 / 6\n",
            "Train  accuracy->38.18 loss->1.09\n",
            "Validate  val_accuracy-->37.03 val_loss-->1.10\n",
            "Epoch 6 / 6\n",
            "Train  accuracy->38.31 loss->1.09\n",
            "Validate  val_accuracy-->37.81 val_loss-->1.10\n",
            "Test Accuracy--->82.50 Test Loss--->0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Classifier- AlexNet"
      ],
      "metadata": {
        "id": "J4EzhWOrf3zI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####DATASET: MINIST05\n",
        "\n",
        "####MODEL NAME: AlexNet\n",
        "\n",
        "####NAME CODE: MINIST05_AlexNet\n",
        "\n",
        "####STATUS: Without Backward Learning"
      ],
      "metadata": {
        "id": "2VTr5VGtf8qK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transition_matrix_M5_Alex_N, train_M5_Alex_N, val_M5_Alex_N, test_M5_Alex_N = MINIST(batch_size=128, name='MINIST05_AlexNet')\n",
        "run_train_val(train_loader=train_M5_Alex_N, val_loader=val_M5_Alex_N, test_loader=test_M5_Alex_N, model_name='AlexNet', lr=0.0002, epoch_num=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxF6mpRjgIqI",
        "outputId": "9b00b09a-5cbb-44cb-ce45-4e183a73fdf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code Name:  MINIST05_AlexNet\n",
            "Setting: MINIST05_AlexNet activated!\n",
            "【New turn...】\n",
            "Epoch 1 / 10\n",
            "Train  accuracy->37.92 loss->1.11\n",
            "Validate  val_accuracy-->45.36 val_loss-->1.06\n",
            "Epoch 2 / 10\n",
            "Train  accuracy->42.01 loss->1.08\n",
            "Validate  val_accuracy-->46.44 val_loss-->1.06\n",
            "Epoch 3 / 10\n",
            "Train  accuracy->42.88 loss->1.08\n",
            "Validate  val_accuracy-->47.00 val_loss-->1.05\n",
            "Epoch 4 / 10\n",
            "Train  accuracy->43.94 loss->1.07\n",
            "Validate  val_accuracy-->47.11 val_loss-->1.05\n",
            "Epoch 5 / 10\n",
            "Train  accuracy->44.63 loss->1.07\n",
            "Validate  val_accuracy-->47.42 val_loss-->1.05\n",
            "Epoch 6 / 10\n",
            "Train  accuracy->44.64 loss->1.07\n",
            "Validate  val_accuracy-->47.97 val_loss-->1.05\n",
            "Epoch 7 / 10\n",
            "Train  accuracy->45.17 loss->1.06\n",
            "Validate  val_accuracy-->47.94 val_loss-->1.05\n",
            "Epoch 8 / 10\n",
            "Train  accuracy->45.42 loss->1.06\n",
            "Validate  val_accuracy-->48.08 val_loss-->1.05\n",
            "Epoch 9 / 10\n",
            "Train  accuracy->45.31 loss->1.06\n",
            "Validate  val_accuracy-->48.06 val_loss-->1.05\n",
            "Epoch 10 / 10\n",
            "Train  accuracy->45.37 loss->1.06\n",
            "Validate  val_accuracy-->48.36 val_loss-->1.05\n",
            "Test Accuracy--->89.23 Test Loss--->0.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####DATASET: MINIST05\n",
        "\n",
        "####MODEL NAME: AlexNet\n",
        "\n",
        "####NAME CODE: MINIST05_AlexNet\n",
        "\n",
        "####STATUS: With Backward Learning"
      ],
      "metadata": {
        "id": "zxwIqsQLgAiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transition_matrix_M5_Alex_Y, train_M5_Alex_Y, val_M5_Alex_Y, test_M5_Alex_Y = MINIST(batch_size=128, name='MINIST05_AlexNet')\n",
        "run_train_val(train_loader=train_M5_Alex_Y, val_loader=val_M5_Alex_Y, test_loader=test_M5_Alex_Y, model_name='AlexNet', transition_matrix=transition_matrix_M5_Alex_Y, lr=0.0002, epoch_num=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GGiGruigJLV",
        "outputId": "c45bf81e-03d8-438f-a65d-8d4372821692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code Name:  MINIST05_AlexNet\n",
            "Setting: MINIST05_AlexNet activated!\n",
            "【New turn...】\n",
            "Epoch 1 / 10\n",
            "Train  accuracy->37.49 loss->1.31\n",
            "Validate  val_accuracy-->46.56 val_loss-->1.06\n",
            "Epoch 2 / 10\n",
            "Train  accuracy->39.11 loss->1.16\n",
            "Validate  val_accuracy-->47.03 val_loss-->1.06\n",
            "Epoch 3 / 10\n",
            "Train  accuracy->40.49 loss->1.12\n",
            "Validate  val_accuracy-->47.47 val_loss-->1.05\n",
            "Epoch 4 / 10\n",
            "Train  accuracy->41.56 loss->1.10\n",
            "Validate  val_accuracy-->47.33 val_loss-->1.05\n",
            "Epoch 5 / 10\n",
            "Train  accuracy->42.73 loss->1.09\n",
            "Validate  val_accuracy-->47.86 val_loss-->1.05\n",
            "Epoch 6 / 10\n",
            "Train  accuracy->42.35 loss->1.09\n",
            "Validate  val_accuracy-->47.58 val_loss-->1.05\n",
            "Epoch 7 / 10\n",
            "Train  accuracy->43.92 loss->1.08\n",
            "Validate  val_accuracy-->47.58 val_loss-->1.05\n",
            "Epoch 8 / 10\n",
            "Train  accuracy->43.72 loss->1.07\n",
            "Validate  val_accuracy-->48.11 val_loss-->1.05\n",
            "Epoch 9 / 10\n",
            "Train  accuracy->44.03 loss->1.07\n",
            "Validate  val_accuracy-->48.28 val_loss-->1.05\n",
            "Epoch 10 / 10\n",
            "Train  accuracy->44.62 loss->1.07\n",
            "Validate  val_accuracy-->48.22 val_loss-->1.05\n",
            "Test Accuracy--->90.27 Test Loss--->0.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####DATASET: MINIST06\n",
        "\n",
        "####MODEL NAME: AlexNet\n",
        "\n",
        "####NAME CODE: MINIST06_AlexNet\n",
        "\n",
        "####STATUS: Without Backward Learning"
      ],
      "metadata": {
        "id": "AZrrOYMDgCT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transition_matrix_M6_Alex_N, train_M6_Alex_N, val_M6_Alex_N, test_M6_Alex_N = MINIST(batch_size=128, name='MINIST06_AlexNet')\n",
        "run_train_val(train_loader=train_M6_Alex_N, val_loader=val_M6_Alex_N, test_loader=test_M6_Alex_N, model_name='AlexNet', lr=0.001, epoch_num=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgCkHj8kgJlr",
        "outputId": "e06e8ae3-28b2-4e67-9081-8590b56b8c2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code Name:  MINIST06_AlexNet\n",
            "Setting: MINIST06_AlexNet activated!\n",
            "【New turn...】\n",
            "Epoch 1 / 5\n",
            "Train  accuracy->34.35 loss->1.13\n",
            "Validate  val_accuracy-->37.25 val_loss-->1.10\n",
            "Epoch 2 / 5\n",
            "Train  accuracy->34.72 loss->1.11\n",
            "Validate  val_accuracy-->37.69 val_loss-->1.09\n",
            "Epoch 3 / 5\n",
            "Train  accuracy->36.38 loss->1.11\n",
            "Validate  val_accuracy-->37.58 val_loss-->1.09\n",
            "Epoch 4 / 5\n",
            "Train  accuracy->36.55 loss->1.10\n",
            "Validate  val_accuracy-->37.22 val_loss-->1.09\n",
            "Epoch 5 / 5\n",
            "Train  accuracy->36.70 loss->1.10\n",
            "Validate  val_accuracy-->37.56 val_loss-->1.09\n",
            "Test Accuracy--->85.10 Test Loss--->1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####DATASET: MINIST06\n",
        "\n",
        "####MODEL NAME: AlexNet\n",
        "\n",
        "####NAME CODE: MINIST05_AlexNet\n",
        "\n",
        "####STATUS: With Backward Learning"
      ],
      "metadata": {
        "id": "Y-3UENMEgEKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transition_matrix_M6_Alex_Y, train_M6_Alex_Y, val_M6_Alex_Y, test_M6_Alex_Y = MINIST(batch_size=256, name='MINIST06_AlexNet')\n",
        "run_train_val(train_loader=train_M6_Alex_Y, val_loader=val_M6_Alex_Y, test_loader=test_M6_Alex_Y, model_name='AlexNet', transition_matrix=transition_matrix_M6_Alex_Y, lr=0.00015, epoch_num=10)"
      ],
      "metadata": {
        "id": "IP3QACDEf8W5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92b2f744-cf1f-4321-b4b0-0610a0f027e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code Name:  MINIST06_AlexNet\n",
            "Setting: MINIST06_AlexNet activated!\n",
            "【New turn...】\n",
            "Epoch 1 / 10\n",
            "Train  accuracy->33.88 loss->2.24\n",
            "Validate  val_accuracy-->34.97 val_loss-->1.12\n",
            "Epoch 2 / 10\n",
            "Train  accuracy->33.83 loss->1.44\n",
            "Validate  val_accuracy-->35.19 val_loss-->1.10\n",
            "Epoch 3 / 10\n",
            "Train  accuracy->33.67 loss->1.28\n",
            "Validate  val_accuracy-->35.92 val_loss-->1.10\n",
            "Epoch 4 / 10\n",
            "Train  accuracy->34.63 loss->1.22\n",
            "Validate  val_accuracy-->36.58 val_loss-->1.10\n",
            "Epoch 5 / 10\n",
            "Train  accuracy->34.42 loss->1.19\n",
            "Validate  val_accuracy-->36.58 val_loss-->1.10\n",
            "Epoch 6 / 10\n",
            "Train  accuracy->34.68 loss->1.17\n",
            "Validate  val_accuracy-->36.86 val_loss-->1.10\n",
            "Epoch 7 / 10\n",
            "Train  accuracy->34.74 loss->1.16\n",
            "Validate  val_accuracy-->36.19 val_loss-->1.10\n",
            "Epoch 8 / 10\n",
            "Train  accuracy->34.88 loss->1.15\n",
            "Validate  val_accuracy-->36.61 val_loss-->1.10\n",
            "Epoch 9 / 10\n",
            "Train  accuracy->34.70 loss->1.14\n",
            "Validate  val_accuracy-->37.64 val_loss-->1.10\n",
            "Epoch 10 / 10\n",
            "Train  accuracy->34.48 loss->1.14\n",
            "Validate  val_accuracy-->37.33 val_loss-->1.10\n",
            "Test Accuracy--->78.60 Test Loss--->1.05\n"
          ]
        }
      ]
    }
  ]
}